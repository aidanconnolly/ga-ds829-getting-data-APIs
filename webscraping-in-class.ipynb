{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Web Scraping\n",
    "\n",
    "_Author: Joseph Nelson (DC)_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Class\n",
    "\n",
    "#### Install Selenium\n",
    "\n",
    "Selenium is a headless browser. It allows us to render JavaScript just as a human-navigated browser would.\n",
    "\n",
    "To install Selenium, use one of the following:\n",
    "- **Anaconda:** `conda install -c conda-forge selenium`\n",
    "- **pip:** `pip install selenium`\n",
    "\n",
    "\n",
    "#### Install GeckoDriver\n",
    "\n",
    "You will also need GeckoDriver (this assumes you are using Homebrew for Mac): \n",
    "\n",
    "- ```brew install geckodriver```\n",
    "\n",
    "#### Install Firefox\n",
    "\n",
    "Additionally, you will need to have downloaded the [Firefox browser](https://www.mozilla.org/en-US/firefox/new/?utm_source=google&utm_medium=cpc&utm_campaign=Firefox-Brand-US-GGL-Exact&utm_term=firefox&utm_content=A144_A203_A006336&gclid=Cj0KEQjwnPLKBRC-j7nt1b7OlZwBEiQAv8lMLJUyReT6cPzSYdmEA6uD3YDoieuuuusddgAU7XH6smEaAoje8P8HAQ&gclsrc=aw.ds) for the application in this lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "- Revisit how to locate elements on a webpage\n",
    "- Aquire unstructure data from the internet using Beautiful soup.\n",
    "- Discuss limitations associated with simple requests and urllib libraries\n",
    "- Introduce Selenium as a solution, and implement a scraper using selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Guide\n",
    "\n",
    "- [Introduction](#intro)\n",
    "- [Building a web scraper](#building-scraper)\n",
    "- [Retrieving data from the HTML page](#retrieving-data)\n",
    "    - [Retrieving the restaurant names](#retrieving-names)\n",
    "    - [Challenge: Retrieving the restaurant locations](#retrieving-locations)\n",
    "    - [Retrieving the restaurant prices](#retrieving-prices)\n",
    "    - [Retrieving the restaurant number of bookings](#retrieving-bookings)\n",
    "\n",
    "\n",
    "- [Introducting Selenium](#selenium)\n",
    "    - [Running JavaScript before scraping](#selenium-js)\n",
    "    - [Using regex to only get digits](#selenium-regex)\n",
    "    - [Challenge: Use Pandas to create a DataFrame of bookings](#challenge-pandas)\n",
    "    - [Auto-typing using Selenium](#selenium-typing)\n",
    "\n",
    "\n",
    "- [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "## Introduction\n",
    "\n",
    "In this codealong lesson, we'll build a web scraper using BeautifulSoup. We will also explore how to use a headless browser called Selenium.\n",
    "\n",
    "We'll begin by scraping Resy's DC listings. We're interested in knowing the restaurant's **name, neighborhood, price, and star ratings.**\n",
    "\n",
    "Resy provides all of this information on this given page: https://resy.com/cities/dc?seats=2&date=2022-08-02\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"retrieving-data\"></a>\n",
    "### Retrieving data from the HTML page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first find each restaurant name listed on the page we've loaded. How do we find the page location of the restaurant? (Hint: We need to know where in the **HTML** the restaurant element is housed.) In order to find the HTML that renders the restaurant location, we can use Google Chrome's Inspect tool:\n",
    "\n",
    "> https://resy.com/cities/dc?seats=2&date=2022-08-02\n",
    "\n",
    "> 1. Visit the URL above. \n",
    "\n",
    "> 2. Right-click on an element you are interested in, then choose Inspect (in Chrome). \n",
    "\n",
    "> 3. This will open the Developer Tools and show the HTML used to render the selected page element. \n",
    "\n",
    "> Throughout this lesson, we will use this method to find tags associated with elements of the page we want to scrape.\n",
    "\n",
    "See if you can find the restaurant name on the page. Keep in mind there are many restaurants loaded on the page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"selenium\"></a>\n",
    "## Introducing Selenium\n",
    "\n",
    "Selenium is a headless browser. It allows us to render JavaScript just as a human-navigated browser would.\n",
    "\n",
    "To install Selenium, use one of the following:\n",
    "- **Anaconda:** `conda install -c conda-forge selenium`\n",
    "- **pip:** `pip install selenium`\n",
    "\n",
    "You will also need GeckoDriver (this assumes you are using Homebrew for Mac): \n",
    "\n",
    "- ```brew install geckodriver```\n",
    "\n",
    "Additionally, you will need to have downloaded the [Firefox browser](https://www.mozilla.org/en-US/firefox/new/?utm_source=google&utm_medium=cpc&utm_campaign=Firefox-Brand-US-GGL-Exact&utm_term=firefox&utm_content=A144_A203_A006336&gclid=Cj0KEQjwnPLKBRC-j7nt1b7OlZwBEiQAv8lMLJUyReT6cPzSYdmEA6uD3YDoieuuuusddgAU7XH6smEaAoje8P8HAQ&gclsrc=aw.ds) for the application in this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selenium requires us to determine a default browser to run. I'm going to opt for Firefox, but Chromium is also a very common choice. http://selenium-python.readthedocs.io/faq.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOP\n",
    "# what is going to happen when I run the next cell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a driver called Firefox\n",
    "driver = webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty crazy, right? Let's close that driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close it\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's boot it up, and visit a URL of our choice\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(\"http://www.python.org\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome. Now we're getting somewhere: programmatically controlling our browser like a human."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit our OpenTable page\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(\"https://resy.com/cities/dc?seats=2&date=2022-08-02\")\n",
    "\n",
    "# always good to check we've got the page we think we do\n",
    "assert \"Resy\" in driver.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Resy | Right This Way'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sleep\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit our relevant page\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(\"https://resy.com/cities/dc?seats=2&date=2022-08-02\")\n",
    "\n",
    "# wait one second\n",
    "sleep(1)\n",
    "\n",
    "#grab the page source\n",
    "html = driver.page_source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pop Quiz:** What do we need to do with this HTML?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeautifulSoup it!\n",
    "html = BeautifulSoup(html, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to always keep in mind the data types that were returned. Note this is a `list`, and we know that immediately by observing the outer square brackets and commas separating each tag.\n",
    "\n",
    "Next, note the elements of the list are `Tag` objects, not strings. (If they were strings, they would be surrounded by quotes.) The Beautiful Soup authors chose to display a `Tag` object visually as a text representation of the tag and its contents. However, being an object, it has many methods that we can call on it. For example, next we will use the `encode_contents()` method to return the tag's contents encoded as a Python string.\n",
    "\n",
    "<a id=\"retrieving-names\"></a>\n",
    "#### Retrieving the restaurant names\n",
    "\n",
    "Now that we found a list of tags containing the restaurant names, let's think how we can loop through them all one-by-one. In the following cell, we'll print out the name (and **only** the clean name, not the rest of the html) of each restaurant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chicken + Whiskey\n",
      "Oyster Oyster\n",
      "The Green Zone\n",
      "Cafe Fili DC\n",
      "CHIKO Dupont Circle\n",
      "The Dabney\n",
      "The Red Hen\n",
      "Rasika West End\n",
      "Rasika Penn Quarter\n",
      "All Purpose\n",
      "Tail Up Goat\n",
      "Rooster & Owl\n",
      "Maydan\n",
      "Sushi Nakazawa DC\n",
      "Ellē\n",
      "Fancy Radish\n",
      "Reveler’s Hour\n",
      "St. Vincent Wine\n"
     ]
    }
   ],
   "source": [
    "# for each element you find, print out the restaurant name\n",
    "for entry in html.find_all('div', {'class': \"SearchResult__title--container\"}):\n",
    "     print(entry.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!\n",
    "\n",
    "<a id=\"retrieving-locations\"></a>\n",
    "#### Challenge: Retrieving the restaurant neighborhoods\n",
    "\n",
    "Can you repeat that process for finding the location? For example, barmini by Jose Andres is in the location listed as \"Penn Quarter\" in our search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"neighborhood\"><i class=\"ResyIcon ResyIcon--pin\"><svg height=\"1em\" viewbox=\"0 0 20 20\" width=\"1em\"><path d=\"m10 1.5c3.5898509 0 6.5 2.91014913 6.5 6.5 0 3.1783736-1.8115848 5.4745544-4.9479735 8.6580075l-.8458482.8488788c-.611314.6003241-.75280912.6319201-1.31466848.094788l-.63253781-.6293629-.60151476-.6104719c-2.92840208-3.0013562-4.65745725-5.2721018-4.65745725-8.3618395 0-3.58985087 2.91014913-6.5 6.5-6.5zm0 4c-1.38071187 0-2.5 1.11928813-2.5 2.5s1.11928813 2.5 2.5 2.5c1.3807119 0 2.5-1.11928813 2.5-2.5s-1.1192881-2.5-2.5-2.5z\" fill-rule=\"evenodd\"></path></svg></i>Logan/ 14th Street Corridor</div>,\n",
       " <div class=\"neighborhood\"><i class=\"ResyIcon ResyIcon--pin\"><svg height=\"1em\" viewbox=\"0 0 20 20\" width=\"1em\"><path d=\"m10 1.5c3.5898509 0 6.5 2.91014913 6.5 6.5 0 3.1783736-1.8115848 5.4745544-4.9479735 8.6580075l-.8458482.8488788c-.611314.6003241-.75280912.6319201-1.31466848.094788l-.63253781-.6293629-.60151476-.6104719c-2.92840208-3.0013562-4.65745725-5.2721018-4.65745725-8.3618395 0-3.58985087 2.91014913-6.5 6.5-6.5zm0 4c-1.38071187 0-2.5 1.11928813-2.5 2.5s1.11928813 2.5 2.5 2.5c1.3807119 0 2.5-1.11928813 2.5-2.5s-1.1192881-2.5-2.5-2.5z\" fill-rule=\"evenodd\"></path></svg></i>Shaw</div>,\n",
       " <div class=\"neighborhood\"><i class=\"ResyIcon ResyIcon--pin\"><svg height=\"1em\" viewbox=\"0 0 20 20\" width=\"1em\"><path d=\"m10 1.5c3.5898509 0 6.5 2.91014913 6.5 6.5 0 3.1783736-1.8115848 5.4745544-4.9479735 8.6580075l-.8458482.8488788c-.611314.6003241-.75280912.6319201-1.31466848.094788l-.63253781-.6293629-.60151476-.6104719c-2.92840208-3.0013562-4.65745725-5.2721018-4.65745725-8.3618395 0-3.58985087 2.91014913-6.5 6.5-6.5zm0 4c-1.38071187 0-2.5 1.11928813-2.5 2.5s1.11928813 2.5 2.5 2.5c1.3807119 0 2.5-1.11928813 2.5-2.5s-1.1192881-2.5-2.5-2.5z\" fill-rule=\"evenodd\"></path></svg></i>Adams Morgan</div>,\n",
       " <div class=\"neighborhood\"><i class=\"ResyIcon ResyIcon--pin\"><svg height=\"1em\" viewbox=\"0 0 20 20\" width=\"1em\"><path d=\"m10 1.5c3.5898509 0 6.5 2.91014913 6.5 6.5 0 3.1783736-1.8115848 5.4745544-4.9479735 8.6580075l-.8458482.8488788c-.611314.6003241-.75280912.6319201-1.31466848.094788l-.63253781-.6293629-.60151476-.6104719c-2.92840208-3.0013562-4.65745725-5.2721018-4.65745725-8.3618395 0-3.58985087 2.91014913-6.5 6.5-6.5zm0 4c-1.38071187 0-2.5 1.11928813-2.5 2.5s1.11928813 2.5 2.5 2.5c1.3807119 0 2.5-1.11928813 2.5-2.5s-1.1192881-2.5-2.5-2.5z\" fill-rule=\"evenodd\"></path></svg></i>Capitol Hill</div>,\n",
       " <div class=\"neighborhood\"><i class=\"ResyIcon ResyIcon--pin\"><svg height=\"1em\" viewbox=\"0 0 20 20\" width=\"1em\"><path d=\"m10 1.5c3.5898509 0 6.5 2.91014913 6.5 6.5 0 3.1783736-1.8115848 5.4745544-4.9479735 8.6580075l-.8458482.8488788c-.611314.6003241-.75280912.6319201-1.31466848.094788l-.63253781-.6293629-.60151476-.6104719c-2.92840208-3.0013562-4.65745725-5.2721018-4.65745725-8.3618395 0-3.58985087 2.91014913-6.5 6.5-6.5zm0 4c-1.38071187 0-2.5 1.11928813-2.5 2.5s1.11928813 2.5 2.5 2.5c1.3807119 0 2.5-1.11928813 2.5-2.5s-1.1192881-2.5-2.5-2.5z\" fill-rule=\"evenodd\"></path></svg></i>Dupont Circle</div>,\n",
       " <div class=\"neighborhood\"><i class=\"ResyIcon ResyIcon--pin\"><svg height=\"1em\" viewbox=\"0 0 20 20\" width=\"1em\"><path d=\"m10 1.5c3.5898509 0 6.5 2.91014913 6.5 6.5 0 3.1783736-1.8115848 5.4745544-4.9479735 8.6580075l-.8458482.8488788c-.611314.6003241-.75280912.6319201-1.31466848.094788l-.63253781-.6293629-.60151476-.6104719c-2.92840208-3.0013562-4.65745725-5.2721018-4.65745725-8.3618395 0-3.58985087 2.91014913-6.5 6.5-6.5zm0 4c-1.38071187 0-2.5 1.11928813-2.5 2.5s1.11928813 2.5 2.5 2.5c1.3807119 0 2.5-1.11928813 2.5-2.5s-1.1192881-2.5-2.5-2.5z\" fill-rule=\"evenodd\"></path></svg></i>Shaw</div>,\n",
       " <div class=\"neighborhood\"><i class=\"ResyIcon ResyIcon--pin\"><svg height=\"1em\" viewbox=\"0 0 20 20\" width=\"1em\"><path d=\"m10 1.5c3.5898509 0 6.5 2.91014913 6.5 6.5 0 3.1783736-1.8115848 5.4745544-4.9479735 8.6580075l-.8458482.8488788c-.611314.6003241-.75280912.6319201-1.31466848.094788l-.63253781-.6293629-.60151476-.6104719c-2.92840208-3.0013562-4.65745725-5.2721018-4.65745725-8.3618395 0-3.58985087 2.91014913-6.5 6.5-6.5zm0 4c-1.38071187 0-2.5 1.11928813-2.5 2.5s1.11928813 2.5 2.5 2.5c1.3807119 0 2.5-1.11928813 2.5-2.5s-1.1192881-2.5-2.5-2.5z\" fill-rule=\"evenodd\"></path></svg></i>Bloomingdale</div>,\n",
       " <div class=\"neighborhood\"><i class=\"ResyIcon ResyIcon--pin\"><svg height=\"1em\" viewbox=\"0 0 20 20\" width=\"1em\"><path d=\"m10 1.5c3.5898509 0 6.5 2.91014913 6.5 6.5 0 3.1783736-1.8115848 5.4745544-4.9479735 8.6580075l-.8458482.8488788c-.611314.6003241-.75280912.6319201-1.31466848.094788l-.63253781-.6293629-.60151476-.6104719c-2.92840208-3.0013562-4.65745725-5.2721018-4.65745725-8.3618395 0-3.58985087 2.91014913-6.5 6.5-6.5zm0 4c-1.38071187 0-2.5 1.11928813-2.5 2.5s1.11928813 2.5 2.5 2.5c1.3807119 0 2.5-1.11928813 2.5-2.5s-1.1192881-2.5-2.5-2.5z\" fill-rule=\"evenodd\"></path></svg></i>West End</div>,\n",
       " <div class=\"neighborhood\"><i class=\"ResyIcon ResyIcon--pin\"><svg height=\"1em\" viewbox=\"0 0 20 20\" width=\"1em\"><path d=\"m10 1.5c3.5898509 0 6.5 2.91014913 6.5 6.5 0 3.1783736-1.8115848 5.4745544-4.9479735 8.6580075l-.8458482.8488788c-.611314.6003241-.75280912.6319201-1.31466848.094788l-.63253781-.6293629-.60151476-.6104719c-2.92840208-3.0013562-4.65745725-5.2721018-4.65745725-8.3618395 0-3.58985087 2.91014913-6.5 6.5-6.5zm0 4c-1.38071187 0-2.5 1.11928813-2.5 2.5s1.11928813 2.5 2.5 2.5c1.3807119 0 2.5-1.11928813 2.5-2.5s-1.1192881-2.5-2.5-2.5z\" fill-rule=\"evenodd\"></path></svg></i>Penn Quarter</div>,\n",
       " <div class=\"neighborhood\"><i class=\"ResyIcon ResyIcon--pin\"><svg height=\"1em\" viewbox=\"0 0 20 20\" width=\"1em\"><path d=\"m10 1.5c3.5898509 0 6.5 2.91014913 6.5 6.5 0 3.1783736-1.8115848 5.4745544-4.9479735 8.6580075l-.8458482.8488788c-.611314.6003241-.75280912.6319201-1.31466848.094788l-.63253781-.6293629-.60151476-.6104719c-2.92840208-3.0013562-4.65745725-5.2721018-4.65745725-8.3618395 0-3.58985087 2.91014913-6.5 6.5-6.5zm0 4c-1.38071187 0-2.5 1.11928813-2.5 2.5s1.11928813 2.5 2.5 2.5c1.3807119 0 2.5-1.11928813 2.5-2.5s-1.1192881-2.5-2.5-2.5z\" fill-rule=\"evenodd\"></path></svg></i>Shaw</div>,\n",
       " <div class=\"neighborhood\"><i class=\"ResyIcon ResyIcon--pin\"><svg height=\"1em\" viewbox=\"0 0 20 20\" width=\"1em\"><path d=\"m10 1.5c3.5898509 0 6.5 2.91014913 6.5 6.5 0 3.1783736-1.8115848 5.4745544-4.9479735 8.6580075l-.8458482.8488788c-.611314.6003241-.75280912.6319201-1.31466848.094788l-.63253781-.6293629-.60151476-.6104719c-2.92840208-3.0013562-4.65745725-5.2721018-4.65745725-8.3618395 0-3.58985087 2.91014913-6.5 6.5-6.5zm0 4c-1.38071187 0-2.5 1.11928813-2.5 2.5s1.11928813 2.5 2.5 2.5c1.3807119 0 2.5-1.11928813 2.5-2.5s-1.1192881-2.5-2.5-2.5z\" fill-rule=\"evenodd\"></path></svg></i>Adams Morgan</div>,\n",
       " <div class=\"neighborhood\"><i class=\"ResyIcon ResyIcon--pin\"><svg height=\"1em\" viewbox=\"0 0 20 20\" width=\"1em\"><path d=\"m10 1.5c3.5898509 0 6.5 2.91014913 6.5 6.5 0 3.1783736-1.8115848 5.4745544-4.9479735 8.6580075l-.8458482.8488788c-.611314.6003241-.75280912.6319201-1.31466848.094788l-.63253781-.6293629-.60151476-.6104719c-2.92840208-3.0013562-4.65745725-5.2721018-4.65745725-8.3618395 0-3.58985087 2.91014913-6.5 6.5-6.5zm0 4c-1.38071187 0-2.5 1.11928813-2.5 2.5s1.11928813 2.5 2.5 2.5c1.3807119 0 2.5-1.11928813 2.5-2.5s-1.1192881-2.5-2.5-2.5z\" fill-rule=\"evenodd\"></path></svg></i>14th Street NW</div>,\n",
       " <div class=\"neighborhood\"><i class=\"ResyIcon ResyIcon--pin\"><svg height=\"1em\" viewbox=\"0 0 20 20\" width=\"1em\"><path d=\"m10 1.5c3.5898509 0 6.5 2.91014913 6.5 6.5 0 3.1783736-1.8115848 5.4745544-4.9479735 8.6580075l-.8458482.8488788c-.611314.6003241-.75280912.6319201-1.31466848.094788l-.63253781-.6293629-.60151476-.6104719c-2.92840208-3.0013562-4.65745725-5.2721018-4.65745725-8.3618395 0-3.58985087 2.91014913-6.5 6.5-6.5zm0 4c-1.38071187 0-2.5 1.11928813-2.5 2.5s1.11928813 2.5 2.5 2.5c1.3807119 0 2.5-1.11928813 2.5-2.5s-1.1192881-2.5-2.5-2.5z\" fill-rule=\"evenodd\"></path></svg></i>14th Street</div>,\n",
       " <div class=\"neighborhood\"><i class=\"ResyIcon ResyIcon--pin\"><svg height=\"1em\" viewbox=\"0 0 20 20\" width=\"1em\"><path d=\"m10 1.5c3.5898509 0 6.5 2.91014913 6.5 6.5 0 3.1783736-1.8115848 5.4745544-4.9479735 8.6580075l-.8458482.8488788c-.611314.6003241-.75280912.6319201-1.31466848.094788l-.63253781-.6293629-.60151476-.6104719c-2.92840208-3.0013562-4.65745725-5.2721018-4.65745725-8.3618395 0-3.58985087 2.91014913-6.5 6.5-6.5zm0 4c-1.38071187 0-2.5 1.11928813-2.5 2.5s1.11928813 2.5 2.5 2.5c1.3807119 0 2.5-1.11928813 2.5-2.5s-1.1192881-2.5-2.5-2.5z\" fill-rule=\"evenodd\"></path></svg></i>East End</div>,\n",
       " <div class=\"neighborhood\"><i class=\"ResyIcon ResyIcon--pin\"><svg height=\"1em\" viewbox=\"0 0 20 20\" width=\"1em\"><path d=\"m10 1.5c3.5898509 0 6.5 2.91014913 6.5 6.5 0 3.1783736-1.8115848 5.4745544-4.9479735 8.6580075l-.8458482.8488788c-.611314.6003241-.75280912.6319201-1.31466848.094788l-.63253781-.6293629-.60151476-.6104719c-2.92840208-3.0013562-4.65745725-5.2721018-4.65745725-8.3618395 0-3.58985087 2.91014913-6.5 6.5-6.5zm0 4c-1.38071187 0-2.5 1.11928813-2.5 2.5s1.11928813 2.5 2.5 2.5c1.3807119 0 2.5-1.11928813 2.5-2.5s-1.1192881-2.5-2.5-2.5z\" fill-rule=\"evenodd\"></path></svg></i>Mount Pleasant</div>,\n",
       " <div class=\"neighborhood\"><i class=\"ResyIcon ResyIcon--pin\"><svg height=\"1em\" viewbox=\"0 0 20 20\" width=\"1em\"><path d=\"m10 1.5c3.5898509 0 6.5 2.91014913 6.5 6.5 0 3.1783736-1.8115848 5.4745544-4.9479735 8.6580075l-.8458482.8488788c-.611314.6003241-.75280912.6319201-1.31466848.094788l-.63253781-.6293629-.60151476-.6104719c-2.92840208-3.0013562-4.65745725-5.2721018-4.65745725-8.3618395 0-3.58985087 2.91014913-6.5 6.5-6.5zm0 4c-1.38071187 0-2.5 1.11928813-2.5 2.5s1.11928813 2.5 2.5 2.5c1.3807119 0 2.5-1.11928813 2.5-2.5s-1.1192881-2.5-2.5-2.5z\" fill-rule=\"evenodd\"></path></svg></i>H Street Corridor</div>,\n",
       " <div class=\"neighborhood\"><i class=\"ResyIcon ResyIcon--pin\"><svg height=\"1em\" viewbox=\"0 0 20 20\" width=\"1em\"><path d=\"m10 1.5c3.5898509 0 6.5 2.91014913 6.5 6.5 0 3.1783736-1.8115848 5.4745544-4.9479735 8.6580075l-.8458482.8488788c-.611314.6003241-.75280912.6319201-1.31466848.094788l-.63253781-.6293629-.60151476-.6104719c-2.92840208-3.0013562-4.65745725-5.2721018-4.65745725-8.3618395 0-3.58985087 2.91014913-6.5 6.5-6.5zm0 4c-1.38071187 0-2.5 1.11928813-2.5 2.5s1.11928813 2.5 2.5 2.5c1.3807119 0 2.5-1.11928813 2.5-2.5s-1.1192881-2.5-2.5-2.5z\" fill-rule=\"evenodd\"></path></svg></i>Lanier Heights</div>,\n",
       " <div class=\"neighborhood\"><i class=\"ResyIcon ResyIcon--pin\"><svg height=\"1em\" viewbox=\"0 0 20 20\" width=\"1em\"><path d=\"m10 1.5c3.5898509 0 6.5 2.91014913 6.5 6.5 0 3.1783736-1.8115848 5.4745544-4.9479735 8.6580075l-.8458482.8488788c-.611314.6003241-.75280912.6319201-1.31466848.094788l-.63253781-.6293629-.60151476-.6104719c-2.92840208-3.0013562-4.65745725-5.2721018-4.65745725-8.3618395 0-3.58985087 2.91014913-6.5 6.5-6.5zm0 4c-1.38071187 0-2.5 1.11928813-2.5 2.5s1.11928813 2.5 2.5 2.5c1.3807119 0 2.5-1.11928813 2.5-2.5s-1.1192881-2.5-2.5-2.5z\" fill-rule=\"evenodd\"></path></svg></i>Park View</div>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first, see if you can identify the location for all elements -- print it out\n",
    "html.find_all('div', {'class': 'neighborhood'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logan/ 14th Street Corridor\n",
      "Shaw\n",
      "Adams Morgan\n",
      "Capitol Hill\n",
      "Dupont Circle\n",
      "Shaw\n",
      "Bloomingdale\n",
      "West End\n",
      "Penn Quarter\n",
      "Shaw\n",
      "Adams Morgan\n",
      "14th Street NW\n",
      "14th Street\n",
      "East End\n",
      "Mount Pleasant\n",
      "H Street Corridor\n",
      "Lanier Heights\n",
      "Park View\n"
     ]
    }
   ],
   "source": [
    "# now print out EACH location for the restaurants\n",
    "for entry in html.find_all('div', {'class': 'neighborhood'}):\n",
    "    print(entry.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's return to our earlier problem: How do we locate bookings on the page?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab just the text of each of these entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we've figured out the restaurant name and neighborhood. Now we need to grab the price (number of dollar signs on a scale of one to four) for each restaurant. We'll follow the same process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"retrieving-prices\"></a>\n",
    "#### Retrieving the restaurant prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks great, but what if I wanted just the number of dollar signs per restaurant? Can you figure out a way to simply print out the number of dollar signs per restaurant listed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$\n",
      "$$$\n",
      "$\n",
      "$$\n",
      "$$\n",
      "$$$\n",
      "$$\n",
      "$$$\n",
      "$$$\n",
      "$$\n",
      "$$\n",
      "$$$\n",
      "$$\n",
      "$$$$\n",
      "$$\n",
      "$$\n",
      "$$\n",
      "$$\n"
     ]
    }
   ],
   "source": [
    "for entry in html.find_all('div', {'class': 'price'}):\n",
    "    print(entry.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of dollars signs per restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cocktail Bar\n",
      "Vegetarian\n",
      "Middle Eastern\n",
      "Mediterranean\n",
      "Asian\n",
      "American\n",
      "Italian\n",
      "Indian\n",
      "Indian\n",
      "Pizza\n",
      "Mediterranean\n",
      "American\n",
      "Middle Eastern\n",
      "Sushi\n",
      "American\n",
      "Vegan\n",
      "American\n",
      "Wine\n"
     ]
    }
   ],
   "source": [
    "# do the same as above, but grabbing only the text content\n",
    "for entry in html.find_all('div', {'class': 'cuisine'}):\n",
    "    print(entry.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0(30)·\n",
      "4.9(868)·\n",
      "4.9(731)·\n",
      "4.9(186)·\n",
      "4.9(117)·\n",
      "4.8(16.7k)·\n",
      "4.8(9.1k)·\n",
      "4.8(9k)·\n",
      "4.8(7.9k)·\n",
      "4.8(7.6k)·\n",
      "4.8(5.8k)·\n",
      "4.8(5.6k)·\n",
      "4.8(5.1k)·\n",
      "4.8(3.3k)·\n",
      "4.8(3.2k)·\n",
      "4.8(2.9k)·\n",
      "4.8(2.5k)·\n",
      "4.8(1.7k)·\n"
     ]
    }
   ],
   "source": [
    "# do the same as above, but grabbing only the text content\n",
    "for entry in html.find_all('div', {'class': 'SearchResult__metadata--rating'}):\n",
    "    print(entry.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before chef Enrique Limardo made a name for himself helming the kitchens at Seven Reasons and Immigrant Food, he was cutting his teeth in D.C. ...\n",
      "Don’t let the name fool you. Oyster Oyster serves up more than just bivalves in its charming and airy space. In fact, much of chef Rob Rubba’s exce...\n",
      "In its mission to highlight the food of the Mid-Atlantic region, The Dabney excels fiercely. That most of its hyper-seasonal dishes are cooked in a ...\n",
      "For those nights when all you want (or need) is a satisfying bowl of pasta and a glass of nice wine, you head straight to one of DC’s coziest and m...\n",
      "One bite into the naan and you’ll understand why Rasika belongs to the city’s fine dining pantheon. This is acclaimed restaurateur Ashok Bajaj’...\n",
      "One bite into the naan and you’ll understand why Rasika belongs to the city’s fine dining pantheon. This is acclaimed restaurateur Ashok Bajaj’...\n",
      "The pizza here is very notably delicious. It’s no wonder chef Mike Friedman got a James Beard Award nom.\n",
      "Owned and operated by a trio of longtime Adams Morgan residents and seasoned industry players, Tail Up Goat is a neighborhood restaurant t...\n",
      "The four-course menu at Rooster & Owl unravels like a flavor-packed reverie, and we’d expect no less from fine-dining vet Yuan Tang, who exto...\n",
      "Rose Previte's Florida Ave. staple brings together traditions from across the Levant and Middle East for one of D.C.'s most irresistible nights out. Fac...\n",
      "Rethink your concept of fish in two hours and 20 bites at Sushi Nakazawa. At a sleek, minimalist counter, chef Daisuke Nakazawa, of Jiro Dreams o...\n",
      "It’s dangerously easy to spend all day at Ellē. A bakery and cafe by day and full-service restaurant by night, the Mount Pleasant eatery wows in eve...\n",
      "Long gone are the days of sad vegetarian eateries, and Fancy Radish simply wows, cleverly subverting peanuts, rutabagas, and mushrooms for dishe...\n",
      "Think the same team behind cult favorite Tail Up Goat, but with way more pasta and a whole lot of wine. Need we say more?\n",
      "Inspired by New Orleans’ Bacchanal Wine, with its mix of garden/wine shop/music venue, bar veterans Frederick Uku (the Red Hen) and Peyt...\n"
     ]
    }
   ],
   "source": [
    "for entry in html.find_all('div', {'class': 'SearchResult__why-we-like-it body--sm color--text-secondary'}):\n",
    "    print(entry.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"challenge-pandas\"></a>\n",
    "### Challenge: Use Pandas to create a DataFrame of bookings\n",
    "\n",
    "However, the bonus is on you to now put all the pieces together.\n",
    "\n",
    "Loop through each entry. For each entry, grab the relevant information we want (name, location, price, bookings). Produce a dataframe with the columns \"name\",\"location\",\"price\",\"bookings\" that contains the 100 entries we would like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm going to create my empty df first\n",
    "dc_eats = pd.DataFrame(columns=[\"name\",\"location\",\"price\",\"star ratings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put code here that populates the DataFrame using Selenium and BeautifulSoup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>price</th>\n",
       "      <th>star ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, location, price, star ratings]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out our work\n",
    "dc_eats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! We succeeded.\n",
    "\n",
    "<a id=\"selenium-typing\"></a>\n",
    "### Auto-typing using Selenium\n",
    "\n",
    "Now, let's explore some of the other functionality of a webdriver. We've barely scratched the surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can send keys as well\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open Firefox\n",
    "driver = webdriver.Firefox()\n",
    "\n",
    "# visit Python\n",
    "driver.get(\"http://www.python.org\")\n",
    "\n",
    "# verify we're in the right place\n",
    "assert \"Python\" in driver.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try automatedly typing `pycon` in the search box and hitting the return key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the search position\n",
    "elem = driver.find_element_by_name(\"q\")\n",
    "\n",
    "# clear it\n",
    "elem.clear()\n",
    "\n",
    "# type in pycon\n",
    "elem.send_keys(\"pycon\")\n",
    "\n",
    "# send those keys\n",
    "elem.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all at once:\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(\"http://www.python.org\")\n",
    "assert \"Python\" in driver.title\n",
    "\n",
    "elem = driver.find_element_by_name(\"q\")\n",
    "elem.clear()\n",
    "elem.send_keys(\"pycon\")\n",
    "elem.send_keys(Keys.RETURN)\n",
    "#assert \"No results found.\" not in driver.page_source\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example (and many others) are available in the Selenium docs: http://selenium-python.readthedocs.io/getting-started.html\n",
    "\n",
    "What is especially important is exploring functionality like locating elements: http://selenium-python.readthedocs.io/locating-elements.html#locating-elements\n",
    "\n",
    "FAQ:\n",
    "http://selenium-python.readthedocs.io/faq.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "In this lesson, we used the Beautiful Soup library to locate elements on a website then scrape their text. We also used the Selenium headless browser to run JavaScript first before retrieving the page contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
